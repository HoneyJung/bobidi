{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c72371",
   "metadata": {},
   "source": [
    "# 0. Get text and tokenize\n",
    "* For n-gram, ignore any special characters, spaces, or punctuations. Only consider alphabets\n",
    "* Make all upper case characters to lower cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c07463f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " king lear\n",
      "====================================================\n",
      "\n",
      " dramatis personae\n",
      "====================================================\n",
      "\n",
      "lear king of britain  king lear\n",
      "====================================================\n",
      "king of france\n",
      "====================================================\n",
      "duke of burgundy burgundy\n",
      "====================================================\n",
      "duke of cornwall cornwall\n",
      "====================================================\n",
      "duke of albany albany\n",
      "====================================================\n",
      "earl of kent kent\n",
      "====================================================\n",
      "earl of gloucester gloucester\n",
      "====================================================\n",
      "edgar son to gloucester\n",
      "====================================================\n",
      "edmund bastard son to gloucester\n",
      "====================================================\n",
      "curan a courtier\n",
      "====================================================\n",
      "old man tenant to gloucester\n",
      "====================================================\n",
      "doctor\n",
      "====================================================\n",
      "fool\n",
      "====================================================\n",
      "oswald steward to goneril\n",
      "====================================================\n",
      " a captain employed by edmund\n",
      "====================================================\n",
      " captain\n",
      "====================================================\n",
      " gentleman attendant on cordelia\n",
      "====================================================\n",
      " gentleman\n",
      "====================================================\n",
      "\n",
      " a herald\n",
      "====================================================\n",
      " servants to cornwall\n",
      "====================================================\n",
      "\n",
      " first servant\n",
      "====================================================\n",
      "\n",
      " second servant\n",
      "====================================================\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "def Get_text_and_tokenize(path_to_text):\n",
    "    f = open(path_to_text, mode='rt', encoding='utf-8')\n",
    "    text = ''\n",
    "    for a in f.read(): # time complexity N\n",
    "        if a.isalpha() or a=='\\t' or a == ' ' or a=='\\n' or a=='.':\n",
    "            text = text + a\n",
    "        if a==';' or a==':':\n",
    "            text = text + '.'\n",
    "\n",
    "    # time complexity N\n",
    "    text = text.lower().replace('\\n\\n', '.').replace('..','.').replace('\\t\\t', '.').replace('\\t',' ')\n",
    "    sentences = text.split('.')\n",
    "    return sentences\n",
    "\n",
    "sentences = Get_text_and_tokenize('kinglear.txt')\n",
    "\n",
    "print(\"DEBUGGING PRINT\")\n",
    "i = 0\n",
    "for sentence in sentences:\n",
    "    if i == 24:\n",
    "        break\n",
    "    print(sentence)\n",
    "    print(\"====================================================\")\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430c1f7c",
   "metadata": {},
   "source": [
    "# 1. Uni_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a501cd2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 910), ('and', 735), ('i', 649), ('to', 570), ('of', 482), ('you', 458), ('my', 457), ('a', 405), ('that', 347), ('king', 310)]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# for test\n",
    "# sentences = [\"My apple is the best apple\"]\n",
    "\n",
    "uni_gram = defaultdict(int)\n",
    "for sentence in sentences:\n",
    "    for word in sentence.split():\n",
    "        uni_gram[word] = uni_gram[word] + 1\n",
    "\n",
    "# sort by hit counts\n",
    "# time complexity nlogn\n",
    "print(sorted(uni_gram.items(), key = lambda item: item[1], reverse = True)[:10])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2bdd5e",
   "metadata": {},
   "source": [
    "# 2. Bi_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "25458839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('king', 'lear'), 234), (('my', 'lord'), 75), (('i', 'am'), 71), (('i', 'have'), 63), (('in', 'the'), 54), (('to', 'the'), 44), (('of', 'the'), 42), (('i', 'will'), 42), (('the', 'king'), 39), (('i', 'know'), 34)]\n"
     ]
    }
   ],
   "source": [
    "bi_gram = defaultdict(int)\n",
    "# for test\n",
    "#sentences = [\"My apple is great, your apple is great, too\"]\n",
    "\n",
    "for sentence in sentences:\n",
    "    words = sentence.split()\n",
    "    # before => One word before\n",
    "    for i in range(len(words)):\n",
    "        if i == 0:\n",
    "            before = words[i]\n",
    "        else:\n",
    "            bi_gram[(before, words[i])] = bi_gram[(before, words[i])] + 1\n",
    "            before = words[i]\n",
    "            \n",
    "# sort by hit counts\n",
    "# time complexity nlogn\n",
    "print(sorted(bi_gram.items(), key = lambda item: item[1], reverse = True)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "51e6898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "def N_gram(n, path_to_text):\n",
    "    sentences = Get_text_and_tokenize(path_to_text)\n",
    "    # for test\n",
    "    sentences = [\"My apple is great, your apple is great, too\"]\n",
    "    N_gram = defaultdict(int)\n",
    "    for sentence in sentences:\n",
    "        before = deque([])\n",
    "        words = sentence.split()\n",
    "        for i in range(len(words)): ###############O(words)\n",
    "            before.append(words[i])\n",
    "            if i >= n-1:\n",
    "                if i != n-1:\n",
    "                    before.popleft()\n",
    "                # deque is unhashable => convert to tuple which is hashable\n",
    "                # O(n)\n",
    "                key = tuple(before) \n",
    "                N_gram[key] = N_gram[key] + 1\n",
    "    \n",
    "    # overall time complexity => O(words * n)\n",
    "    # overall space complexity => O(unique N-gram set + n)\n",
    "    \n",
    "    # sort by hit counts\n",
    "    # time complexity nlogn\n",
    "    result = sorted(N_gram.items(), key = lambda item: item[1], reverse = True)[:10]\n",
    "    return result\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fc024dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('apple', 'is'), 2), (('is', 'great,'), 2), (('My', 'apple'), 1), (('great,', 'your'), 1), (('your', 'apple'), 1), (('great,', 'too'), 1)]\n"
     ]
    }
   ],
   "source": [
    "print(N_gram(2, 'shakespears_all.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0584fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
