{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91bb8c9a",
   "metadata": {},
   "source": [
    "# 0. Get text and tokenize\n",
    "* For n-gram, ignore any special characters, spaces, or punctuations. Only consider alphabets\n",
    "* Make all upper case characters to lower cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c07463f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUGGING PRINT\n",
      "king  lear\n",
      "====================================================\n",
      "\n",
      "dramatis  personae\n",
      "====================================================\n",
      "\n",
      "learking  of  britain    king  lear\n",
      "====================================================\n",
      "king  of  france\n",
      "====================================================\n",
      "duke  of  burgundyburgundy\n",
      "====================================================\n",
      "duke  of  cornwallcornwall\n",
      "====================================================\n",
      "duke  of  albanyalbany\n",
      "====================================================\n",
      "earl  of  kentkent\n",
      "====================================================\n",
      "earl  of  gloucestergloucester\n",
      "====================================================\n",
      "edgarson  to  gloucester\n",
      "====================================================\n",
      "edmundbastard  son  to  gloucester\n",
      "====================================================\n",
      "curana  courtier\n",
      "====================================================\n",
      "old  mantenant  to  gloucester\n",
      "====================================================\n",
      "doctor\n",
      "====================================================\n",
      "fool\n",
      "====================================================\n",
      "oswaldsteward  to  goneril\n",
      "====================================================\n",
      "a  captain  employed  by  edmund\n",
      "====================================================\n",
      "  captain\n",
      "====================================================\n",
      "gentleman  attendant  on  cordelia\n",
      "====================================================\n",
      "  gentleman\n",
      "====================================================\n",
      "\n",
      "a  herald\n",
      "====================================================\n",
      "servants  to  cornwall\n",
      "====================================================\n",
      "\n",
      "first  servant\n",
      "====================================================\n",
      "\n",
      "second  servant\n",
      "====================================================\n",
      "\n",
      "third  servant\n",
      "====================================================\n",
      "\n",
      "goneril\n",
      "====================================================\n",
      "regan    daughters  to  lear\n",
      "====================================================\n",
      "cordelia\n",
      "====================================================\n",
      "\n",
      "knights  of  lears  train  captains  messengers\n",
      "soldiers  and  attendants\n",
      "knight\n",
      "====================================================\n",
      "\n",
      "captain\n",
      "====================================================\n",
      "\n",
      "messenger\n",
      "====================================================\n",
      "\n",
      "====================================================\n",
      "scenebritain\n",
      "====================================================\n",
      "\n",
      "====================================================\n",
      "\n",
      "king  lear\n",
      "====================================================\n",
      "\n",
      "act  i\n",
      "====================================================\n",
      "scene  iking  lears  palace\n",
      "====================================================\n",
      "\n",
      "enter  kent  gloucester  and  edmund\n",
      "====================================================\n",
      "kenti  thought  the  king  had  more  affected  the  duke  of\n",
      "albany  than  cornwall\n",
      "====================================================\n",
      "gloucesterit  did  always  seem  so  to  us\n",
      "====================================================\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "def Get_text_and_tokenize(path_to_text):\n",
    "    f = open(path_to_text, mode='rt', encoding='utf-8')\n",
    "    text = ''\n",
    "    for a in f.read(): # time complexity N\n",
    "        if a.isalpha() or a == ' ' or a=='\\n' or a=='.':\n",
    "            text = text + a\n",
    "        if a==';' or a==':' or a=='\\t\\t':\n",
    "            text = text + '.'\n",
    "        if a==' ':\n",
    "            text = text + ' '\n",
    "\n",
    "    # time complexity N\n",
    "    text = text.lower().replace('\\n\\n', '.').replace('..','.')#.replace('\\t\\t', '.').replace('\\t',' ')\n",
    "    sentences = text.split('.')\n",
    "    return sentences\n",
    "\n",
    "sentences = Get_text_and_tokenize('kinglear.txt')\n",
    "\n",
    "print(\"DEBUGGING PRINT\")\n",
    "i = 0\n",
    "for sentence in sentences:\n",
    "    if i == 40:\n",
    "        break\n",
    "    print(sentence)\n",
    "    print(\"====================================================\")\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430c1f7c",
   "metadata": {},
   "source": [
    "# 1. Uni_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a501cd2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 880), ('and', 723), ('i', 558), ('to', 555), ('of', 480), ('you', 442), ('my', 439), ('a', 382), ('that', 342), ('king', 308)]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# for test\n",
    "# sentences = [\"My apple is the best apple\"]\n",
    "\n",
    "uni_gram = defaultdict(int)\n",
    "for sentence in sentences:\n",
    "    for word in sentence.split():\n",
    "        uni_gram[word] = uni_gram[word] + 1\n",
    "\n",
    "# sort by hit counts\n",
    "# time complexity nlogn\n",
    "print(sorted(uni_gram.items(), key = lambda item: item[1], reverse = True)[:10])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2bdd5e",
   "metadata": {},
   "source": [
    "# 2. Bi_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "25458839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('my', 'lord'), 69), (('i', 'am'), 62), (('i', 'have'), 57), (('in', 'the'), 54), (('king', 'lear'), 47), (('to', 'the'), 44), (('of', 'the'), 42), (('the', 'king'), 36), (('i', 'will'), 35), (('and', 'the'), 30)]\n"
     ]
    }
   ],
   "source": [
    "bi_gram = defaultdict(int)\n",
    "# for test\n",
    "#sentences = [\"My apple is great, your apple is great, too\"]\n",
    "\n",
    "for sentence in sentences:\n",
    "    words = sentence.split()\n",
    "    # before => One word before\n",
    "    for i in range(len(words)):\n",
    "        if i == 0:\n",
    "            before = words[i]\n",
    "        else:\n",
    "            bi_gram[(before, words[i])] = bi_gram[(before, words[i])] + 1\n",
    "            before = words[i]\n",
    "            \n",
    "# sort by hit counts\n",
    "# time complexity nlogn\n",
    "print(sorted(bi_gram.items(), key = lambda item: item[1], reverse = True)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "51e6898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "def N_gram(n, path_to_text):\n",
    "    sentences = Get_text_and_tokenize(path_to_text)\n",
    "    \n",
    "    # for test\n",
    "    #sentences = [\"My apple is great, your apple is great, too\"]\n",
    "    \n",
    "    N_gram = defaultdict(int)\n",
    "    for sentence in sentences:\n",
    "        before = deque([])\n",
    "        words = sentence.split()\n",
    "        for i in range(len(words)): ###############O(words)\n",
    "            before.append(words[i])\n",
    "            if i >= n-1:\n",
    "                if i != n-1:\n",
    "                    before.popleft()\n",
    "                # deque is unhashable => convert to tuple which is hashable\n",
    "                # O(n)\n",
    "                key = tuple(before) \n",
    "                N_gram[key] = N_gram[key] + 1\n",
    "    \n",
    "    # overall time complexity => O(words * n)\n",
    "    # overall space complexity => O(unique N-gram set + n)\n",
    "    \n",
    "    # sort by hit counts\n",
    "    # time complexity nlogn\n",
    "    result = sorted(N_gram.items(), key = lambda item: item[1], reverse = True)[:10]\n",
    "    return result\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fc024dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('apple', 'is', 'great,'), 2), (('My', 'apple', 'is'), 1), (('is', 'great,', 'your'), 1), (('great,', 'your', 'apple'), 1), (('your', 'apple', 'is'), 1), (('is', 'great,', 'too'), 1)]\n"
     ]
    }
   ],
   "source": [
    "print(N_gram(3, 'shakespears_all.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0584fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
